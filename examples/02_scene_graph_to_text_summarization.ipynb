{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scene Graph to Text Summarization\n",
        "\n",
        "This notebook demonstrates how to convert scene graphs into natural language descriptions and generate summaries using various text summarization models.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. **Scene Graph Processing**: Load and process scene graph data\n",
        "2. **Text Generation**: Convert scene graph triples to natural language\n",
        "3. **Summarization**: Generate concise summaries using different models\n",
        "4. **Evaluation**: Compare different summarization approaches\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Make sure you have the required dependencies installed:\n",
        "```bash\n",
        "pip install torch transformers sentencepiece protobuf\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "# Add the src directory to the path\n",
        "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
        "\n",
        "# Import m3sgg summarization components\n",
        "from m3sgg.language.summarization.summarize import (\n",
        "    linearize_triples,\n",
        "    summarize_sentences,\n",
        "    summarize_with_pegasus_separate,\n",
        "    summarize_with_pegasus_custom\n",
        ")\n",
        "from m3sgg.language.summarization.wrappers import (\n",
        "    T5SummarizationWrapper,\n",
        "    PegasusSummarizationWrapper,\n",
        "    PegasusCustomConfig,\n",
        "    PegasusSeparateLoader\n",
        ")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Sample Scene Graph Data\n",
        "\n",
        "Let's start with some sample scene graph data to demonstrate the summarization process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample scene graph triples\n",
        "sample_triples = [\n",
        "    (\"person\", \"holding\", \"cup\"),\n",
        "    (\"person\", \"sitting on\", \"chair\"),\n",
        "    (\"person\", \"looking at\", \"laptop\"),\n",
        "    (\"laptop\", \"on\", \"table\"),\n",
        "    (\"cup\", \"on\", \"table\"),\n",
        "    (\"person\", \"wearing\", \"glasses\"),\n",
        "    (\"person\", \"touching\", \"keyboard\"),\n",
        "    (\"laptop\", \"in front of\", \"person\"),\n",
        "    (\"chair\", \"behind\", \"table\"),\n",
        "    (\"person\", \"drinking from\", \"cup\")\n",
        "]\n",
        "\n",
        "print(\"Sample scene graph triples:\")\n",
        "for i, triple in enumerate(sample_triples, 1):\n",
        "    subject, predicate, obj = triple\n",
        "    print(f\"{i:2d}. {subject} --{predicate}--> {obj}\")\n",
        "\n",
        "print(f\"\\nTotal triples: {len(sample_triples)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Convert Triples to Natural Language\n",
        "\n",
        "Convert the scene graph triples into natural language sentences using the linearization function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert triples to natural language sentences\n",
        "sentences = linearize_triples(sample_triples)\n",
        "\n",
        "print(\"Natural language sentences:\")\n",
        "print(\"=\" * 50)\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"{i:2d}. {sentence}\")\n",
        "\n",
        "print(f\"\\nTotal sentences: {len(sentences)}\")\n",
        "\n",
        "# Combine all sentences into a single text\n",
        "combined_text = \" \".join(sentences)\n",
        "print(f\"\\nCombined text length: {len(combined_text)} characters\")\n",
        "print(f\"Combined text: {combined_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Summarization with Different Models\n",
        "\n",
        "Now let's generate summaries using different summarization models and compare their outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to safely run summarization with error handling\n",
        "def safe_summarize(sentences, model_type=\"t5\", model_name=None, **kwargs):\n",
        "    \"\"\"Safely run summarization with error handling.\n",
        "    \n",
        "    :param sentences: List of sentences to summarize\n",
        "    :param model_type: Type of model to use ('t5' or 'pegasus')\n",
        "    :param model_name: Specific model name to use\n",
        "    :param kwargs: Additional arguments for summarization\n",
        "    :return: Summary text or error message\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if model_type.lower() == \"t5\":\n",
        "            model_name = model_name or \"google-t5/t5-base\"\n",
        "            summary = summarize_sentences(sentences, model_name=model_name, model_type=\"t5\")\n",
        "        elif model_type.lower() == \"pegasus\":\n",
        "            model_name = model_name or \"google/pegasus-xsum\"\n",
        "            summary = summarize_sentences(sentences, model_name=model_name, model_type=\"pegasus\")\n",
        "        else:\n",
        "            return f\"Unsupported model type: {model_type}\"\n",
        "        \n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error with {model_type}: {str(e)}\"\n",
        "\n",
        "# Test different summarization approaches\n",
        "print(\"Testing different summarization models...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# T5 Summarization\n",
        "print(\"T5 Summarization:\")\n",
        "print(\"-\" * 30)\n",
        "t5_summary = safe_summarize(sentences, model_type=\"t5\")\n",
        "print(f\"Summary: {t5_summary}\")\n",
        "print()\n",
        "\n",
        "# Pegasus Summarization\n",
        "print(\"Pegasus Summarization:\")\n",
        "print(\"-\" * 30)\n",
        "pegasus_summary = safe_summarize(sentences, model_type=\"pegasus\")\n",
        "print(f\"Summary: {pegasus_summary}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Summarization Techniques\n",
        "\n",
        "Let's explore more advanced summarization techniques with custom configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Pegasus configurations\n",
        "print(\"Advanced Pegasus Summarization:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Pegasus with separate loader\n",
        "print(\"Pegasus Separate Loader:\")\n",
        "print(\"-\" * 30)\n",
        "try:\n",
        "    pegasus_separate_summary = summarize_with_pegasus_separate(sentences)\n",
        "    print(f\"Summary: {pegasus_separate_summary}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "print()\n",
        "\n",
        "# Pegasus with custom configuration\n",
        "print(\"Pegasus Custom Configuration:\")\n",
        "print(\"-\" * 30)\n",
        "try:\n",
        "    pegasus_custom_summary = summarize_with_pegasus_custom(\n",
        "        sentences, \n",
        "        max_length=80, \n",
        "        min_length=15, \n",
        "        length_penalty=1.5, \n",
        "        num_beams=6\n",
        "    )\n",
        "    print(f\"Summary: {pegasus_custom_summary}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Batch Processing and Comparison\n",
        "\n",
        "Let's process multiple scene graphs and compare the summarization results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple scene graph examples\n",
        "scene_graphs = [\n",
        "    {\n",
        "        \"name\": \"Office Scene\",\n",
        "        \"triples\": [\n",
        "            (\"person\", \"sitting on\", \"chair\"),\n",
        "            (\"person\", \"looking at\", \"computer\"),\n",
        "            (\"person\", \"typing on\", \"keyboard\"),\n",
        "            (\"computer\", \"on\", \"desk\"),\n",
        "            (\"person\", \"wearing\", \"glasses\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Kitchen Scene\", \n",
        "        \"triples\": [\n",
        "            (\"person\", \"standing in\", \"kitchen\"),\n",
        "            (\"person\", \"holding\", \"knife\"),\n",
        "            (\"person\", \"cutting\", \"vegetables\"),\n",
        "            (\"vegetables\", \"on\", \"cutting board\"),\n",
        "            (\"person\", \"wearing\", \"apron\")\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Living Room Scene\",\n",
        "        \"triples\": [\n",
        "            (\"person\", \"sitting on\", \"sofa\"),\n",
        "            (\"person\", \"watching\", \"television\"),\n",
        "            (\"person\", \"holding\", \"remote\"),\n",
        "            (\"television\", \"in front of\", \"sofa\"),\n",
        "            (\"person\", \"drinking from\", \"coffee cup\")\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Process each scene graph\n",
        "results = []\n",
        "\n",
        "for scene in scene_graphs:\n",
        "    print(f\"Processing {scene['name']}...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Convert to sentences\n",
        "    scene_sentences = linearize_triples(scene['triples'])\n",
        "    print(\"Original sentences:\")\n",
        "    for sentence in scene_sentences:\n",
        "        print(f\"  - {sentence}\")\n",
        "    \n",
        "    # Generate summary\n",
        "    summary = safe_summarize(scene_sentences, model_type=\"t5\")\n",
        "    print(f\"Summary: {summary}\")\n",
        "    \n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"name\": scene['name'],\n",
        "        \"sentences\": scene_sentences,\n",
        "        \"summary\": summary,\n",
        "        \"num_triples\": len(scene['triples'])\n",
        "    })\n",
        "    \n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "print(f\"Processed {len(results)} scene graphs successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary Analysis and Metrics\n",
        "\n",
        "Let's analyze the summarization results and compute some basic metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze summarization results\n",
        "def analyze_summaries(results):\n",
        "    \"\"\"Analyze summarization results and compute metrics.\n",
        "    \n",
        "    :param results: List of summarization results\n",
        "    :return: Dictionary with analysis metrics\n",
        "    \"\"\"\n",
        "    analysis = {\n",
        "        \"total_scenes\": len(results),\n",
        "        \"avg_triples_per_scene\": 0,\n",
        "        \"avg_sentences_per_scene\": 0,\n",
        "        \"avg_summary_length\": 0,\n",
        "        \"compression_ratios\": [],\n",
        "        \"successful_summaries\": 0\n",
        "    }\n",
        "    \n",
        "    total_triples = 0\n",
        "    total_sentences = 0\n",
        "    total_summary_chars = 0\n",
        "    \n",
        "    for result in results:\n",
        "        total_triples += result[\"num_triples\"]\n",
        "        total_sentences += len(result[\"sentences\"])\n",
        "        \n",
        "        summary = result[\"summary\"]\n",
        "        if not summary.startswith(\"Error\"):\n",
        "            analysis[\"successful_summaries\"] += 1\n",
        "            total_summary_chars += len(summary)\n",
        "            \n",
        "            # Calculate compression ratio\n",
        "            original_length = sum(len(s) for s in result[\"sentences\"])\n",
        "            compression_ratio = len(summary) / original_length if original_length > 0 else 0\n",
        "            analysis[\"compression_ratios\"].append(compression_ratio)\n",
        "    \n",
        "    analysis[\"avg_triples_per_scene\"] = total_triples / len(results)\n",
        "    analysis[\"avg_sentences_per_scene\"] = total_sentences / len(results)\n",
        "    analysis[\"avg_summary_length\"] = total_summary_chars / max(analysis[\"successful_summaries\"], 1)\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "# Perform analysis\n",
        "analysis = analyze_summaries(results)\n",
        "\n",
        "print(\"Summarization Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total scenes processed: {analysis['total_scenes']}\")\n",
        "print(f\"Successful summaries: {analysis['successful_summaries']}\")\n",
        "print(f\"Average triples per scene: {analysis['avg_triples_per_scene']:.1f}\")\n",
        "print(f\"Average sentences per scene: {analysis['avg_sentences_per_scene']:.1f}\")\n",
        "print(f\"Average summary length: {analysis['avg_summary_length']:.1f} characters\")\n",
        "\n",
        "if analysis['compression_ratios']:\n",
        "    avg_compression = sum(analysis['compression_ratios']) / len(analysis['compression_ratios'])\n",
        "    print(f\"Average compression ratio: {avg_compression:.2f}\")\n",
        "    print(f\"Compression range: {min(analysis['compression_ratios']):.2f} - {max(analysis['compression_ratios']):.2f}\")\n",
        "\n",
        "print(\"\\nDetailed Results:\")\n",
        "print(\"-\" * 30)\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"{i}. {result['name']}\")\n",
        "    print(f\"   Triples: {result['num_triples']}, Sentences: {len(result['sentences'])}\")\n",
        "    print(f\"   Summary: {result['summary'][:100]}{'...' if len(result['summary']) > 100 else ''}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export and Save Results\n",
        "\n",
        "Finally, let's export the summarization results for further use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results to JSON\n",
        "def export_summarization_results(results, analysis, output_path=\"summarization_results.json\"):\n",
        "    \"\"\"Export summarization results to JSON format.\n",
        "    \n",
        "    :param results: List of summarization results\n",
        "    :param analysis: Analysis metrics\n",
        "    :param output_path: Path to save the JSON file\n",
        "    :return: Dictionary with exported data\n",
        "    \"\"\"\n",
        "    export_data = {\n",
        "        \"metadata\": {\n",
        "            \"timestamp\": \"2024-01-01T00:00:00\",  # Would use datetime.now().isoformat() in real usage\n",
        "            \"total_scenes\": analysis[\"total_scenes\"],\n",
        "            \"successful_summaries\": analysis[\"successful_summaries\"],\n",
        "            \"avg_compression_ratio\": sum(analysis[\"compression_ratios\"]) / len(analysis[\"compression_ratios\"]) if analysis[\"compression_ratios\"] else 0\n",
        "        },\n",
        "        \"analysis\": analysis,\n",
        "        \"results\": results\n",
        "    }\n",
        "    \n",
        "    # Save to file\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(export_data, f, indent=2)\n",
        "    \n",
        "    print(f\"Results exported to {output_path}\")\n",
        "    return export_data\n",
        "\n",
        "# Export results\n",
        "export_data = export_summarization_results(results, analysis)\n",
        "print(f\"Exported {len(export_data['results'])} scene graph summarization results\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nExport Summary:\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"File: summarization_results.json\")\n",
        "print(f\"Scenes: {export_data['metadata']['total_scenes']}\")\n",
        "print(f\"Successful: {export_data['metadata']['successful_summaries']}\")\n",
        "print(f\"Avg compression: {export_data['metadata']['avg_compression_ratio']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated the complete pipeline for converting scene graphs to text summaries:\n",
        "\n",
        "1. **Scene Graph Processing**: Loaded and processed scene graph triples\n",
        "2. **Text Generation**: Converted triples to natural language using the `linearize_triples` function\n",
        "3. **Summarization**: Applied different summarization models (T5, Pegasus) with various configurations\n",
        "4. **Batch Processing**: Processed multiple scene graphs and compared results\n",
        "5. **Analysis**: Computed metrics like compression ratios and success rates\n",
        "6. **Export**: Saved results for further analysis\n",
        "\n",
        "### Key Features Demonstrated\n",
        "\n",
        "- **Multiple Models**: T5 and Pegasus summarization models\n",
        "- **Custom Configurations**: Advanced settings for different use cases\n",
        "- **Error Handling**: Robust error handling for model loading and inference\n",
        "- **Batch Processing**: Efficient processing of multiple scene graphs\n",
        "- **Metrics and Analysis**: Comprehensive analysis of summarization quality\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try different model architectures (BART, GPT-based models)\n",
        "- Experiment with different summarization prompts\n",
        "- Integrate with video processing pipeline (see next notebook)\n",
        "- Explore domain-specific summarization approaches\n",
        "- Implement evaluation metrics (ROUGE, BLEU, etc.)\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. **Model Loading Errors**: Ensure transformers library is properly installed\n",
        "2. **Memory Issues**: Use smaller models or reduce batch sizes\n",
        "3. **CUDA Errors**: Check GPU availability and model compatibility\n",
        "4. **Import Errors**: Verify the m3sgg package is properly installed\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
