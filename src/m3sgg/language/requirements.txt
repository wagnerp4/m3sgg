# LLM and Language Model Dependencies
# Core transformers library for model loading and inference
transformers>=4.30.0

# PyTorch for model execution
torch>=2.0.0

# Optional: Accelerate for model optimization
accelerate>=0.20.0

# Optional: BitsAndBytesConfig for quantization (memory efficiency)
bitsandbytes>=0.39.0

# Optional: Flash Attention for faster inference
flash-attn>=2.0.0

# Streamlit for chat interface
streamlit>=1.28.0
streamlit-chat>=0.1.1

# Additional utilities
numpy>=1.21.0
pandas>=1.3.0
